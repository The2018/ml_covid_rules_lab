{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification rules for covid dataset\n",
    "\n",
    "\n",
    "## 1. Classification Rules Implementation\n",
    "\n",
    "### 1.1. PRISM algorithm\n",
    "In this lab we are going to implement the PRISM algorithm to extract the classification rules with the highest accuracy and coverage from the hospital patients dataset described in the class demo notebook.\n",
    "\n",
    "Our algorithm extracts the rules ranked by the accuracy (from highest to lowest), and the ties are broken by choosing the rule with higher coverage. If both accuracy and coverage are the same - the condition is selected arbitrarily.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first implement the algorithm for learning one rule. Besides the dataset, we also pass two optional parameter:\n",
    "\n",
    "the accuracy threshold - the number from 0 to 1 which specifies which rules are considered valid. If after refining the rules and still within the coverage threshold you reach the best accuracy which is below the threshold, you do not add these rules to your solution.\n",
    "\n",
    "the coverage threshold - the absolute number of records covered by the rule. If the more precise rule covers less records than this threshold, the algorithm should stop refining this rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_one_rule(data, accur_threshold, coverage_threshold):\n",
    "    # Find class labels and attributes from data\n",
    "    columns = list(data.columns)\n",
    "    class_labels = columns[-1]\n",
    "    attributes = columns[:-1]\n",
    "    \n",
    "    # Initialize the rule with empty lhs\n",
    "    rule_lhs = []\n",
    "    rule = [rule_lhs,\"\"]\n",
    "    cur_attr = attributes\n",
    "    cur_data = data\n",
    "    cur_rule = rule[:]\n",
    "\n",
    "    while cur_attr:\n",
    "        # For each attribute a not mentioned in the rule, and each attr value v, consider adding the condition a = v to rule_lhs\n",
    "        best_accur = 0\n",
    "        best_pair = []\n",
    "        best_class = \"\"\n",
    "        best_coverage = 0\n",
    "        best_accur_so_far = -1\n",
    "\n",
    "        for clas in cur_data[class_labels].unique():\n",
    "            cur_data = cur_data[cur_data[class_labels]==clas]\n",
    "            for a in cur_attr:\n",
    "                if cur_data[a].dtypes != np.int64 or np.float64:\n",
    "                    values = cur_data[a].unique()\n",
    "                else:\n",
    "                    values = cur_data[a].mean()\n",
    "                \n",
    "                for v in values:\n",
    "                    cur_rule[0] = [a,v]\n",
    "                    cur_rule[1] = clas\n",
    "\n",
    "                    # compute accuracy and coverage\n",
    "                    if cur_data[a].dtype != \"int64\" or \"float64\":\n",
    "                        correct = cur_data[(cur_data[a]==v) & (cur_data[class_labels]==clas)].shape[0]\n",
    "                        coverage = cur_data[cur_data[a]==v].shape[0]\n",
    "                        accur = correct / coverage\n",
    "                    else:\n",
    "                        correct = cur_data[(cur_data[a]>=v) & (cur_data[class_labels]==clas)].shape[0]\n",
    "                        coverage = cur_data[cur_data[a]>=v].shape[0]\n",
    "                        accur = correct / coverage\n",
    "            \n",
    "                    # select the rule of the attribute,value pair with best accuracy\n",
    "                    if (accur > best_accur):\n",
    "                        best_accur = accur\n",
    "                        best_pair = [a,v]\n",
    "                        best_class = clas\n",
    "                        best_coverage = coverage\n",
    "                    elif (accur == best_accur):\n",
    "                        cur_correct = coverage\n",
    "                        correct_so_far = cur_data[(cur_data[best_pair[0]]==best_pair[1]) & (cur_data[class_labels]==clas)].shape[0]\n",
    "                        if cur_correct > correct_so_far:\n",
    "                            best_pair = [a,v]\n",
    "                            best_class = clas\n",
    "                            best_coverage = coverage\n",
    "#         print(best_accur_so_far,best_coverage,(accur > accur_threshold),best_pair)\n",
    "        \n",
    "        # check coverage threshold and if the accuracy does not improve break\n",
    "        if (best_coverage < coverage_threshold) or (best_accur_so_far==best_accur):\n",
    "            if len(best_pair)!=0:\n",
    "                a,v = best_pair[0],best_pair[1]\n",
    "                cur_attr.remove(a)\n",
    "                cur_data = data[data[a]==v]\n",
    "                data = data[data[a]!=v]\n",
    "            break\n",
    "            \n",
    "        # check coverage threshold and add condition a = v to the LHS of rule R\n",
    "        if (best_coverage >= coverage_threshold):\n",
    "            if best_accur > accur_threshold:\n",
    "                rule[0].append(best_pair)\n",
    "                rule[1] = best_class\n",
    "                if len(best_pair)!=0:\n",
    "                    a,v = best_pair[0],best_pair[1]\n",
    "                    cur_attr.remove(a)\n",
    "                    cur_data = data[data[a]==v]\n",
    "                    data = data[data[a]!=v]\n",
    "                    \n",
    "        if data.empty:\n",
    "            break\n",
    "    return rule,data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prism(data,accur_threshold, coverage_threshold):\n",
    "    rules = []\n",
    "    while data.shape[0] > 0:\n",
    "        rule,data = learn_one_rule(data,accur_threshold, coverage_threshold)\n",
    "        if len(rule[0]) >0:\n",
    "            rules.append(rule)\n",
    "    return rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_rules(data,rules):\n",
    "    columns = list(data.columns)\n",
    "    class_labels = columns[-1]\n",
    "    attributes = columns[:-1]\n",
    "    \n",
    "    for r in rules:\n",
    "        print(\"If \",end=\"\")\n",
    "        for ele in r[0]:\n",
    "            data = data[(data[ele[0]]==ele[1])]\n",
    "            print(\"{} = '{}', \".format(ele[0],ele[1]),end=\"\")\n",
    "            \n",
    "        coverage = data.shape[0]\n",
    "        correct = data[data[class_labels]==r[1]].shape[0]\n",
    "        accur = correct / coverage\n",
    "        print(\"then {} = '{}'\".format(class_labels,r[1]))\n",
    "        print(\"Accuracy: {}, Coverage: {}\".format(accur, coverage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test the above function with a toy example of weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[\"s\",\"h\",\"y\"],[\"s\",\"h\",\"y\"],[\"r\",\"c\",\"n\"],[\"s\",\"h\",\"n\"],[\"r\",\"c\",\"y\"]]\n",
    "data = pd.DataFrame (data,columns=['Outlook','Temp','Play'])\n",
    "# rule,data = learn_one_rule(data,0.9,1)\n",
    "rules = prism(data,0.9,2)\n",
    "print_rules(data,rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Coronavirus dataset application\n",
    "\n",
    "Finally, we can apply the algorithm to the COVID-19 dataset to learn reliable rules which determine which symptoms/preexisting conditions and their combination lead to the deadly outcomes of the COVID-19 infection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tis Mexican dataset which contains the information from the Statistical Yearbooks of Morbidity 2015-2017 (as well as the information regarding cases associated with COVID-19) was found on [kaggle](https://www.kaggle.com/tanmoyx/covid19-patient-precondition-dataset).\n",
    "\n",
    "This preprocessed dataset contains only patients that tested positive for COVID-19 and with symptom atributes converted to categorical.\n",
    "\n",
    "In this dataset we have the following attributes:\n",
    "1. sex: 1 -woman, 2-man\n",
    "2. age: numeric\n",
    "3. diabetes: yes/no\n",
    "4. copd (chronic obstructive pulmonary disease): yes/no\n",
    "5. asthma: yes/no\n",
    "6. imm_supr (suppressed immune system): yes/no\n",
    "7. hypertension: yes/no\n",
    "8. cardiovascular: yes/no\n",
    "9. renal_chronic: yes/no\n",
    "10. tobacco: yes/no\t\n",
    "11. outcome: alive/dead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"../data_set/covid_categorical_good.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_file)\n",
    "data = data.dropna(how=\"any\")\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rows = data.to_numpy().tolist()\n",
    "len(data_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_list = data.columns.to_numpy().tolist()\n",
    "print(columns_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Using classification algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rules = prism(data,0.8,20)\n",
    "print_rules(data,rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We discover that with classification algorithm the rules for covid dataset are:\n",
    "\n",
    "If imm_supr = 'no', copd = 'no', asthma = 'no', renal_chronic = 'no', cardiovascular = 'no', then outcome = 'alive'\n",
    "\n",
    "If the patient has no suppressed immune system, no chronic obstructive pulmonary disease, no asthma, no cardiovascular discease, then the rule indicated that he or she will very likely be alive after tested positive for covid. \n",
    "\n",
    "Accuracy: 0.8902581098724516, Coverage: 199140"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
